{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multitask_train_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Inc3KzHR0aS"
      },
      "source": [
        "!pip install pims av\n",
        "!python --version\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pims\n",
        "from tqdm.notebook import trange\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import plot\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w6mVVtXR8xw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbtz-16uR_8r"
      },
      "source": [
        "# CONSTANTS\n",
        "# network input resolution\n",
        "W = 320\n",
        "H = 160\n",
        "\n",
        "# annotations' resolution\n",
        "annot_W = 480\n",
        "annot_H = 320"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUuiN4MWCWMF"
      },
      "source": [
        "# DATA FUNCTIONS\n",
        "from os import listdir\n",
        "\n",
        "# get polylines from file\n",
        "def extract_polylines(filename):\n",
        "  tree = ET.parse(filename)\n",
        "  polylines = []\n",
        "  for polyline in tree.iter(tag='polyline'):\n",
        "    frame = polyline.get(\"frame\")\n",
        "    points = polyline.get(\"points\").split(\";\")\n",
        "    for i in range(len(points)):\n",
        "      points[i] = points[i].split(\",\")\n",
        "      for j in range(len(points[i])):\n",
        "        points[i][j] = float(points[i][j])\n",
        "    data = (int(frame), points)\n",
        "    polylines.append(data)\n",
        "\n",
        "  return sorted(polylines)\n",
        "\n",
        "# get polylines from each frame\n",
        "def extract_frame_lines(polylines):\n",
        "  n_frames = polylines[-1][0]\n",
        "  frames = []\n",
        "\n",
        "  for i in range(n_frames+1):\n",
        "    frame = []\n",
        "    for polyline in polylines:\n",
        "      if polyline[0] == i:\n",
        "        frame.append(polyline[1])\n",
        "    frames.append(sorted(frame))\n",
        "    \n",
        "  return frames\n",
        "\n",
        "# convert annotations to new resolution\n",
        "def convert_annotations(old_res, new_res, annotations):\n",
        "  W, H = old_res\n",
        "  new_W, new_H = new_res\n",
        "  new_annotations = []\n",
        "  for polylines in annotations:\n",
        "    new_polylines = []\n",
        "    for polyline in polylines:\n",
        "      new_polyline = []\n",
        "      for point in polyline:\n",
        "        x, y = point\n",
        "        new_x = (x*new_W) / W\n",
        "        new_y = (y*new_H) / H\n",
        "        new_polyline.append([new_x,new_y])\n",
        "      new_polylines.append(new_polyline)\n",
        "    new_annotations.append(new_polylines)\n",
        "  return np.array(new_annotations)\n",
        "\n",
        "# get training data from path\n",
        "def get_data(video_path, annotations_path):\n",
        "  # get video frames\n",
        "  frames = pims.Video(video_path, format=\"mp4\")\n",
        "  \n",
        "  # get road edges data\n",
        "  annotations = extract_polylines(annotations_path)\n",
        "  annotations = extract_frame_lines(annotations)\n",
        "  annotations = convert_annotations((annot_W,annot_H), (W,H), annotations)\n",
        "\n",
        "  return frames, annotations\n",
        "\n",
        "# make pims video into actual numpy frames\n",
        "def conv_frames(frames):\n",
        "  imgs = []\n",
        "  print(\"Getting frames into proper arrays\")\n",
        "  for frame in frames:\n",
        "    imgs.append(cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (W,H)))\n",
        "  print(\"Frames converted to numpy arrays\")\n",
        "  return np.array(imgs)\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/OpenCRD_dataset/\"\n",
        "video_files = []\n",
        "annot_files = []\n",
        "for f in listdir(base_dir):\n",
        "  if f.endswith(\".mp4\"):\n",
        "    video_files.append(f)\n",
        "  elif f.endswith(\".xml\"):\n",
        "    annot_files.append(f)\n",
        "video_files, annot_files = sorted(video_files), sorted(annot_files)\n",
        "\n",
        "video_files = video_files[:3] # TODO: this is a temp hack, need to get all videos' annotations\n",
        "print(video_files)\n",
        "print(annot_files)\n",
        "\n",
        "assert len(video_files) == len(annot_files), \"Number of video files != number of annotation files\"\n",
        "\n",
        "# POLYLINES TRANSFORMATIONS\n",
        "\n",
        "# TODO: this algorithm has bad complexity (O(n^3)), refactor if possible\n",
        "# convert polylines per frame to net output vector (flattens the array)\n",
        "def serialize_polylines(polylines, n_coords, n_points, max_n_lines):\n",
        "  # check if we have more than n_points\n",
        "  # TODO: instead of removing the whole line, just get polyline[:n_points]\n",
        "  for polyline in polylines.copy():\n",
        "    if len(polyline) != n_points:\n",
        "      polylines.remove(polyline)\n",
        "  assert len(polylines) <= max_n_lines, \"More than max number of lines found\"\n",
        "\n",
        "  # fill the gaps with negative values (-1 or -10 or -100 == NULL => out of bounds)\n",
        "  if len(polylines) < max_n_lines:\n",
        "    for i in range(max_n_lines - len(polylines)):\n",
        "      new_polyline = []\n",
        "      for j in range(n_points):\n",
        "        point = []\n",
        "        for k in range(n_coords):\n",
        "          point.append(-100.)\n",
        "        new_polyline.append(point)\n",
        "      polylines.append(new_polyline)\n",
        "      \n",
        "  # flatten\n",
        "  ret = []\n",
        "  for i in range(max_n_lines):\n",
        "    for j in range(n_points):\n",
        "      for k in range(n_coords):\n",
        "        ret.append(polylines[i][j][k])\n",
        "\n",
        "  return np.array(ret)\n",
        "\n",
        "# TODO: this needs more work depending on the net output, since it is tested only on annotations\n",
        "# convert network output vector to polylines per frame\n",
        "def deserialize_polylines(net_output, n_coords, n_points, max_n_lines):\n",
        "  polylines = []\n",
        "  point = []\n",
        "  line = []\n",
        "  for i in range(len(net_output)):\n",
        "    point.append(net_output[i])\n",
        "    if len(point) == 2:\n",
        "      line.append(point)\n",
        "      point = []\n",
        "    if len(line) == 4:\n",
        "      polylines.append(line)\n",
        "      line = []\n",
        "\n",
        "  # remove (-1, -1)/out-of-bounds points from lines\n",
        "  for polyline in polylines:\n",
        "    while [-100., -100.] in polyline:\n",
        "      #polyline.remove([-100., -100.]) # TODO: remove all negative numbers, not just (-1., -1.) pairs\n",
        "      polyline.remove([-100., -100.])\n",
        "\n",
        "  # remove empty lists\n",
        "  while [] in polylines:\n",
        "    polylines.remove([])\n",
        "\n",
        "  return np.array(polylines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiLgxP9gC4B4"
      },
      "source": [
        "# MODEL DEFINITION\n",
        "\n",
        "# ResNet block\n",
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
        "    super(ResBlock, self).__init__()\n",
        "\n",
        "    self.num_layers = num_layers\n",
        "    if self.num_layers > 34:\n",
        "      self.expansion = 4\n",
        "    else:\n",
        "      self.expansion =1\n",
        "\n",
        "    # ResNet50, 101 and 152 include additional layer of 1x1 kernels\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    if self.num_layers > 34:\n",
        "      self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    else:\n",
        "      # for ResNet18 and 34, connect input directly to 3x3 kernel (skip first 1x1)\n",
        "      self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.elu = nn.ELU()\n",
        "    self.identity_downsample = identity_downsample\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    if self.num_layers > 34:\n",
        "      x = self.elu(self.bn1(self.conv1(x)))\n",
        "    x = self.elu(self.bn2(self.conv2(x)))\n",
        "    x = self.bn3(self.conv3(x))\n",
        "    \n",
        "    if self.identity_downsample is not None:\n",
        "      identity = self.identity_downsample(identity)\n",
        "    x += identity\n",
        "    x = self.elu(x)\n",
        "    return x\n",
        "\n",
        "# Multitask Model\n",
        "class ComboModel(nn.Module):\n",
        "  def __init__(self, num_layers=18, block=ResBlock, image_channels=3):\n",
        "    assert num_layers in [18, 34, 50, 101, 152], \"Unknown ResNet architecture, number of layers must be 18, 34, 50, 101 or 152\"\n",
        "    super(ComboModel, self).__init__()\n",
        "\n",
        "    # polylines' shape\n",
        "    self.n_coords = 2  # 2 coordinates: x,y\n",
        "    self.n_points = 4  # number of points of each polyline\n",
        "    self.max_n_lines = 6 # max number of polylines per frame\n",
        "\n",
        "    if num_layers < 50:\n",
        "      self.expansion = 1\n",
        "    else:\n",
        "      self.expansion = 4\n",
        "    if num_layers == 18:\n",
        "      layers = [2, 2, 2, 2]\n",
        "    elif num_layers == 34 or num_layers == 50:\n",
        "      layers = [3, 4, 23, 3]\n",
        "    elif num_layers == 101:\n",
        "      layers = [3, 8, 23, 3]\n",
        "    else:\n",
        "      layers = [3, 8, 36, 3]\n",
        "\n",
        "    self.in_channels = 16\n",
        "    self.conv1 = nn.Conv2d(image_channels, 16, kernel_size=7, stride=2, padding=3)  # TODO: maybe kernel 5x5\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.elu = nn.ELU()\n",
        "    self.avgpool1 = nn.AvgPool2d(3, 2, padding=1)\n",
        "\n",
        "    # ResNet Layers\n",
        "    self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
        "    self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
        "    self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
        "    self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
        "\n",
        "    self.avgpool2 = nn.AvgPool2d(1, 1)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    self.cr_head = get_cr_head()\n",
        "    self.re_head = get_re_head()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.avgpool1(self.elu(self.bn1(self.conv1(x))))\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.avgpool2(x)\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    cr = torch.sigmoid(self.cr_head(x))\n",
        "    re = self.re_head(x)\n",
        "    return cr, re\n",
        "\n",
        "  def get_cr_head(self):\n",
        "    relu = nn.ReLU()\n",
        "    fc1 = nn.Linear(256*5*10, 1024) # NOTE: this works only with ResNet18\n",
        "    bn1 = nn.BatchNorm1d(1024)\n",
        "    fc2 = nn.Linear(1024, 128)\n",
        "    bn2 = nn.BatchNorm1d(128)\n",
        "    fc3 = nn.Linear(128, 84)\n",
        "    bn3 = nn.BatchNorm1d(84)\n",
        "    fc4 = nn.Linear(84, 1)\n",
        "\n",
        "    head = nn.Sequential(fc1, bn1, relu, fc2, bn2, relu, fc3, bn3, relu, fc4)\n",
        "    return head\n",
        "\n",
        "  def get_re_head(self):\n",
        "    l_relu = nn.LeakyReLU()\n",
        "    fc1 = nn.Linear(512*5*10, 8192) # NOTE: this works only with ResNet18\n",
        "    bn1 = nn.BatchNorm1d(8192)\n",
        "    fc2 = nn.Linear(8192, 4096)\n",
        "    bn2 = nn.BatchNorm1d(4096)\n",
        "    fc3 = nn.Linear(4096, 2048)\n",
        "    bn3 = nn.BatchNorm1d(2048)\n",
        "    fc4 = nn.Linear(2048, 1024)\n",
        "    bn4 = nn.BatchNorm1d(1024)\n",
        "    fc5 = nn.Linear(1024, 512)\n",
        "    bn5 = nn.BatchNorm1d(512)\n",
        "    fc6 = nn.Linear(512, 256)\n",
        "    bn6 = nn.BatchNorm1d(256)\n",
        "    fc7 = nn.Linear(256, 128)\n",
        "    bn7 = nn.BatchNorm1d(128)\n",
        "    fc8 = nn.Linear(128, 64)\n",
        "    bn8 = nn.BatchNorm1d(64)\n",
        "    fc9 = nn.Linear(64, self.n_coords*self.n_points*self.max_n_lines)\n",
        "\n",
        "    head = nn.Sequential(fc1, bn1, l_relu, fc2, bn2, l_relu, fc3, bn3, l_relu,\n",
        "                         fc4, bn4, l_relu, fc5, bn5, l_relu, fc6, bn6, l_relu,\n",
        "                         fc8, bn8, l_relu, fc9)\n",
        "    return head\n",
        "\n",
        "# TODO: progress bar and loss/accuracy for each epoch instead of each sub-iteration + different graphs for each task"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECZM6OaBWJUE"
      },
      "source": [
        "# LOSS WRAPPER\n",
        "\n",
        "class ComboLoss(nn.Module):\n",
        "  def __init__(self, task_num, model):\n",
        "    super(ComboLoss, self).__init__()\n",
        "    self.task_num = task_num  # TODO: maybe make this constant\n",
        "    self.model = model\n",
        "    self.log_vars = nn.Parameter(torch.zeros((task_num)))\n",
        "\n",
        "  def forward(self, preds, cr, re):\n",
        "    bce, mse = nn.BCELoss(), nn.MSELoss()\n",
        "\n",
        "    loss0 = bce(preds[0], cr)\n",
        "    precision0 = torch.exp(-self.log_vars[0])\n",
        "    loss1 = mse(preds[1], re)\n",
        "    precision1 = torch.exp(-self.log_vars[1])\n",
        "\n",
        "    # TODO: need better multitask loss (weighted sum maybe)\n",
        "    return loss0 + loss1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}