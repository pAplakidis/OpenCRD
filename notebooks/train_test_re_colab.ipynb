{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_test_re_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J43Uxe-_v40e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f6e568-b01b-415a-c4b4-c9905edf8a97"
      },
      "source": [
        "!pip install pims av\n",
        "!python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pims\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/47/82e0ac31e01a271e5a06362fbf03769e9081956f6772f91d98b32899d743/PIMS-0.5.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.9MB/s \n",
            "\u001b[?25hCollecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 80kB/s \n",
            "\u001b[?25hCollecting slicerator>=0.9.8\n",
            "  Downloading https://files.pythonhosted.org/packages/75/ae/fe46f5371105508a209fe6162e7e7b11db531a79d2eabcd24566b8b1f534/slicerator-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.8 in /usr/local/lib/python3.7/dist-packages (from pims) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pims) (1.19.5)\n",
            "Building wheels for collected packages: pims\n",
            "  Building wheel for pims (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pims: filename=PIMS-0.5-cp37-none-any.whl size=84328 sha256=e5115a8a0a6099eef2f930682737eccd2a8dd7087c10a9fa2b6c14824bfdd4ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/0a/14/4c33a4cc1b9158e57329a38e8e3e03901ed24060eb322d5462\n",
            "Successfully built pims\n",
            "Installing collected packages: slicerator, pims, av\n",
            "Successfully installed av-8.0.3 pims-0.5 slicerator-1.0.0\n",
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4kCKW_9zuKa",
        "outputId": "47a15cd7-6e0c-4f69-a893-16c679f1a7d2"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pims\n",
        "from tqdm.notebook import trange\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import plot\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3055616/45929032 bytes (6.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7200768/45929032 bytes (15.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11354112/45929032 bytes (24.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13901824/45929032 bytes (30.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16957440/45929032 bytes (36.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20979712/45929032 bytes (45.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24330240/45929032 bytes (53.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28385280/45929032 bytes (61.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32088064/45929032 bytes (69.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36134912/45929032 bytes (78.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40124416/45929032 bytes (87.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44072960/45929032 bytes (96.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xLV2Mq3z15s",
        "outputId": "7bed7e94-646e-41ab-ee15-5937e6aa46b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzVs-kMjz9mf"
      },
      "source": [
        "# CONSTANTS\n",
        "# network input resolution\n",
        "W = 320\n",
        "H = 160\n",
        "\n",
        "# annotations' resolution\n",
        "annot_W = 480\n",
        "annot_H = 320"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKurT2YC0e_9",
        "outputId": "bb5968ec-ba39-4fc2-8bae-4b26266b6b3d"
      },
      "source": [
        "# DATA FUNCTIONS\n",
        "from os import listdir\n",
        "\n",
        "# get polylines from file\n",
        "def extract_polylines(filename):\n",
        "  tree = ET.parse(filename)\n",
        "  polylines = []\n",
        "  for polyline in tree.iter(tag='polyline'):\n",
        "    frame = polyline.get(\"frame\")\n",
        "    points = polyline.get(\"points\").split(\";\")\n",
        "    for i in range(len(points)):\n",
        "      points[i] = points[i].split(\",\")\n",
        "      for j in range(len(points[i])):\n",
        "        points[i][j] = float(points[i][j])\n",
        "    data = (int(frame), points)\n",
        "    polylines.append(data)\n",
        "\n",
        "  return sorted(polylines)\n",
        "\n",
        "# get polylines from each frame\n",
        "def extract_frame_lines(polylines):\n",
        "  n_frames = polylines[-1][0]\n",
        "  frames = []\n",
        "\n",
        "  for i in range(n_frames+1):\n",
        "    frame = []\n",
        "    for polyline in polylines:\n",
        "      if polyline[0] == i:\n",
        "        frame.append(polyline[1])\n",
        "    frames.append(sorted(frame))\n",
        "    \n",
        "  return frames\n",
        "\n",
        "# convert annotations to new resolution\n",
        "def convert_annotations(old_res, new_res, annotations):\n",
        "  W, H = old_res\n",
        "  new_W, new_H = new_res\n",
        "  new_annotations = []\n",
        "  for polylines in annotations:\n",
        "    new_polylines = []\n",
        "    for polyline in polylines:\n",
        "      new_polyline = []\n",
        "      for point in polyline:\n",
        "        x, y = point\n",
        "        new_x = (x*new_W) / W\n",
        "        new_y = (y*new_H) / H\n",
        "        new_polyline.append((new_x,new_y))\n",
        "      new_polylines.append(new_polyline)\n",
        "    new_annotations.append(new_polylines)\n",
        "  return np.array(new_annotations, dtype=object)\n",
        "\n",
        "# get training data from path\n",
        "def get_data(video_path, annotations_path):\n",
        "  # get video frames\n",
        "  frames = pims.Video(video_path, format=\"mp4\")\n",
        "  \n",
        "  # get road edges data\n",
        "  annotations = extract_polylines(annotations_path)\n",
        "  annotations = extract_frame_lines(annotations)\n",
        "  annotations = convert_annotations((annot_W,annot_H), (W,H), annotations)\n",
        "\n",
        "# make pims video into actual numpy frames\n",
        "def conv_frames(frames):\n",
        "  imgs = []\n",
        "  print(\"Getting frames into proper arrays\")\n",
        "  for frame in frames:\n",
        "    imgs.append(cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (W,H)))\n",
        "  print(\"Frames converted to numpy arrays\")\n",
        "  return np.array(imgs)\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/OpenCRD_dataset/\"\n",
        "video_files = []\n",
        "annot_files = []\n",
        "for f in listdir(base_dir):\n",
        "  if f.endswith(\".mp4\"):\n",
        "    video_files.append(f)\n",
        "  elif f.endswith(\".xml\"):\n",
        "    annot_files.append(f)\n",
        "video_files, annot_files = sorted(video_files), sorted(annot_files)\n",
        "\n",
        "video_files = video_files[:2] # TODO: this is a temp hack, need to get all videos' annotations\n",
        "print(video_files)\n",
        "print(annot_files)\n",
        "\n",
        "assert len(video_files) == len(annot_files)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['city_1.mp4', 'city_2.mp4']\n",
            "['city_1_annotations.xml', 'city_2_annotations.xml']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59yJCqCs4MZ4"
      },
      "source": [
        "# PYTOCH MODEL\n",
        "# model for road edge detection\n",
        "class REDetector(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(REDetector, self).__init__()\n",
        "\n",
        "    # output polylines attributes\n",
        "    n_coords = 2  # 2 coordinates: x,y\n",
        "    n_points = 4  # number of points of each polyline\n",
        "    max_n_lines = 6 # max number of polylines per frame\n",
        "\n",
        "    # Convolutional Layers\n",
        "    self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "    self.conv2d_bn1 = nn.BatchNorm2d(16)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "    self.conv2d_bn2 = nn.BatchNorm2d(32)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 5)\n",
        "    self.conv2d_bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    self.fc1 = nn.Linear(64*16*36, 120) # for 320x160 image 64 channels\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=84)\n",
        "    self.fc3 = nn.Linear(84, n_coords*n_points*max_n_lines)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv2_bn1(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.conv2_bn2(self.conv2(x))))\n",
        "    x = self.pool(F.relu(self.conv2_bn3(self.conv3(x))))\n",
        "    #print(x.shape)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.bn1(self.fc1(x)))\n",
        "    x = F.relu(self.bn2(self.fc2(x)))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngKojfEC7weT"
      },
      "source": [
        "# TRAINING PROCESS\n",
        "def train(frames, annotations, model):\n",
        "  loss_function = nn.MSELoss()\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=0.001)  # TODO: try new learning rates\n",
        "\n",
        "  losses, accuracies = [], []\n",
        "  epochs = 11\n",
        "  BS = 128\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(\"[+] Epoch\", epoch)\n",
        "    t = trange(0, len(frames)-BS, BS)\n",
        "    for i in t: \n",
        "      # get data into network\n",
        "      rng = np.random.default_rng()\n",
        "      samp = rng.choice((frames), size=BS, replace=False)\n",
        "\n",
        "      # TODO: get annotations to the output (need a serialize/deserialize function)\n",
        "      X_train = []\n",
        "      Y_train = []\n",
        "      for j in samp:\n",
        "        frame = frames[j]\n",
        "        frame = np.moveaxis(frame, -1, 0) # [batch_size, channels, height, width]\n",
        "        X_train.append(frame)\n",
        "        #Y_train.append([annotations[j]])\n",
        "      samp = []\n",
        "      X = torch.tensor(np.array(X_train)).float().to(device)\n",
        "      #Y = torch.tensor(np.array(Y_train)).float().to(device)\n",
        "\n",
        "      # forward and back feed\n",
        "      optim.zero_grad()\n",
        "      out = model(X)\n",
        "      accuracy = (out == Y).float().mean()  # TODO: this might be wrong\n",
        "      loss = loss_function(out, Y)\n",
        "      loss = loss.mean()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "      # print stats\n",
        "      loss = loss.item()\n",
        "      accuracy = accuracy.item()\n",
        "      losses.append(loss/100) # /100 so that we can see it in the graph\n",
        "      accuracies.append(accuracy)\n",
        "      t.set_description(\"loss %.2f accuracy %.2f out %.2f\" % (loss, accuracy, out.mean().item()))\n",
        "\n",
        "  # plot losses and accuracies\n",
        "  plt.ylim(-0.1, 1.1)\n",
        "  plot(losses)\n",
        "  plot(accuracies)\n",
        "\n",
        "  return model\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "  torch.cuda.empty_cache()  # to avoid running out of cuda memory\n",
        "  print(\"[~] Cleared cuda cache\")\n",
        "\n",
        "model = REDetector().to(device).train()\n",
        "\n",
        "for i in trange(len(video_files)):\n",
        "  print(\"[~] Loading from files: %s , %s\" % (base_dir+video_files[i], base_dir+annot_files[i]))\n",
        "  frames, annotations = get_data(base_dir+video_files[i], base_dir+annot_files[i])\n",
        "  frames = conv_frames(frames)\n",
        "  if i == 0:\n",
        "    all_frames = frames\n",
        "    all_annotations = annotations\n",
        "  else:\n",
        "    all_frames = np.concatenate((all_frames, frames), axis=0)\n",
        "    all_annotations = np.concatenate((all_annotations, annotations), axis=0)\n",
        "\n",
        "franes, labels = [], [] # free up memory\n",
        "print(\"[+] Training mode ...\")\n",
        "model = train(all_frames, all_annotations, model)\n",
        "print(\"[+] Trained model on all data files\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}