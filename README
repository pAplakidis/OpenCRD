My Thesis for my computer science and telecommunications degree

Subject: Monocular Crossroad Detection and Path Prediction (Self-Driving Cars)


GOAL -> Use single camera and solve the following tasks:
*build a net that detects corssroads (+ how far they are?, might not be possible without SLAM, so may not do that)
*build a net that finds different paths in crossroads (maybe use a SLAM library for that or build my own pathfinder)(not something fancy, just need to draw path of turn, then it's back to basic cruising) 
*select a path based on GPS data (just the command: left, right, straight)

NOTES:
- always full stop in crossroads for safety, no matter the sign (might be good to detect it though)
- maybe add small side front facing cameras and SLAM based on all three cameras for crossroad navigation
- either make the images/frames from the cameras panoramic (might be slower but it works with monocular SLAM) or use SLAM for 3 cameras (better precision)
- upload labeled data somewhere

IMPORTANT:
- no more than one camera or SLAM needed since this is just path prediction and not navigation
- need lots of varied datasets (need to label them as well, <crossroad/no-crossroad>, <path car followed>)
- DIFFERENT TYPES OF CROSSROADS (net's outputs cannot be binary)
- get argmax(outputs) to get the estimated crossroad type (need a dictionary as well)
- Convolutional Neural Net for Detection and Recurrent (using 2 images at a time?) for path planning (need to ground truth desire as well, for later GPS usage)
- check out [https://medium.com/@mankaran32/end-to-end-motion-planning-with-deep-learning-comma-ais-approach-5886268515d3 ]

TODO:
- make a script using cv2 that lets me label frames, labels go to a txt file with the same name as the video, each line represents frame label (non crossroad videos should be pretty straightforward)
- preprocess the data (need YUV images for the networks)
- make a training script that goes through all videos and their text-files (labels) and puts the data together for training
- design and train the conv-neural-net (repeat until accuracy is correct) (don't forget to make a test dataset)

- repeat the process for paths (need to convert lines from visual (using drawing or something) to pitch-yaw coordinates like in the new comma.ai calibration challenge)

- find a good GPS API and just query it for directions

Inspiration Content:
- Comma.ai Research [ https://github.com/commaai/research ]
- Comma.ai Calibration Challenge [ https://github.com/commaai/calib_challenge ]
- Andrej Karpathy's lectures and presentation (Tesla Autonomy day, etc)

